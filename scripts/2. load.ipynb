{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58677a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "'''\n",
    "We are going to load data from MongoDB to AWS S3\n",
    "\n",
    "'''\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "from settings import CHANNEL_ID, MAX_RESULTS, DB_NAME, VIDEO_COLLECTION, COMMENT_COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd055ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['credentials.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the configparser module to read the credentials.ini file\n",
    "\n",
    "'''\n",
    "If the file is not found, config.read will not throw an error but will return an empty list and the sections will be empty\n",
    "\n",
    "'''\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('credentials.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d01e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mongodb configuration\n",
    "\n",
    "client = MongoClient(config['MONGODB']['uri'])\n",
    "db = client[DB_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get videos and convert to DataFrame\n",
    "\n",
    "videos = list(db[VIDEO_COLLECTION].find()) # find() operation on the mongodb should be returning documents that we will convert into dataframe\n",
    "video_df = pd.DataFrame(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20902ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id', 'kind', 'etag', 'id', 'snippet']\n"
     ]
    }
   ],
   "source": [
    "# printing a list of all columns in the dataframe\n",
    "\n",
    "print(video_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cf3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Add partition columns for S3 bucket\n",
    "\n",
    "video_df['publishedAt'] = pd.to_datetime(video_df['snippet'].apply(lambda x: x['publishedAt']))\n",
    "video_df['year'] = video_df['publishedAt'].dt.year\n",
    "video_df['month'] = video_df['publishedAt'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id', 'kind', 'etag', 'id', 'snippet', 'publishedAt', 'year', 'month']\n"
     ]
    }
   ],
   "source": [
    "# updated list of columns in the dataframe\n",
    "\n",
    "print(video_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bbf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of records in the dataframe\n",
    "\n",
    "len(video_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eadbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3 partitioned\n",
    "\n",
    "# setting up S3 client\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=config['AWS']['access_key'],\n",
    "    aws_secret_access_key=config['AWS']['secret_key']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the transformed data to AWS S3, partitioned by year and month\n",
    "\n",
    "for (year, month), group in video_df.groupby(['year', 'month']):\n",
    "    csv_data = group.to_csv(index=False)\n",
    "    s3_key = f\"videos/{year}/{month}/data.csv\" # writing as .csv files\n",
    "    s3.put_object(\n",
    "        Bucket=config['AWS']['bucket_name'],\n",
    "        Key=s3_key,\n",
    "        Body=csv_data\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
